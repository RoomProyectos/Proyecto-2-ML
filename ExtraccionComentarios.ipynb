{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 - ML\n",
    "#### Grupo 1:  Gledson - Eva - Sara - Rubén - Luis Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - - Importación de módulos y librerías - - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from Scrappers.Scrapper_Comentarios import extrae_comentarios_meneo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de URLS\n",
    "Cargamos el dataset de \"Meneos\" para utilizar las URL como índice sobre el cual iterar para extraer los comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274376, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_completo = pd.read_csv(\"Data/MeneosCompleto.csv\", sep=\";\")\n",
    "df_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos Nans y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274364,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_URLs = df_completo[df_completo[\"URL\"].isna() == False][\"URL\"]\n",
    "df_URLs = df_URLs.drop_duplicates()\n",
    "df_URLs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucle para el Scrapping de Comentarios\n",
    "\n",
    "Es posible establecer el límite de comentarios que se quiere extraer. Decidimos extaer 100.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "limite_comentarios = 100000\n",
    "contador_comentarios = 0\n",
    "lista_aux_comentarios = [] \n",
    "\n",
    "# Recorremos el listado de enlaces para extraer los comentarios de cada noticia\n",
    "for meneo in df_URLs:\n",
    "    # Mientras no hayamos superado el contador, continuamos recorriendo el bucle de URLs\n",
    "    if contador_comentarios < limite_comentarios:\n",
    "        pagina_comentarios = 1\n",
    "\n",
    "        # Accedemos a la URL con el sufijo \"standard\" para disponer de los comentarios ordenados\n",
    "        browser.get(f\"{meneo}/standard/\")\n",
    "        Soup_pagina_meneo = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "        # Si la noticia tiene más de 100 comentarios, obtenemos el número de páginas de comentarios que tiene\n",
    "        try:\n",
    "            total_paginas_comentarios = int(Soup_pagina_meneo.find(\"div\", class_=\"pages\")[\"data-total-pages\"])\n",
    "        except:\n",
    "            total_paginas_comentarios = 1\n",
    "\n",
    "        # En función del número de páginas, las recorremos mientras haya\n",
    "        while pagina_comentarios <= total_paginas_comentarios:\n",
    "            if pagina_comentarios == 1:\n",
    "                resultado = extrae_comentarios_meneo(Soup_pagina_meneo, pagina_comentarios)\n",
    "            else:\n",
    "                browser.get(f\"{meneo}/standard/{pagina_comentarios}\")\n",
    "                Soup_pagina_meneo = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "                resultado = extrae_comentarios_meneo(Soup_pagina_meneo, pagina_comentarios)\n",
    "            \n",
    "            # Almacenamos los comentarios en una lista y actualizamos el contador\n",
    "            lista_aux_comentarios.extend(resultado)\n",
    "            contador_comentarios += len(resultado)\n",
    "            pagina_comentarios += 1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos los resultado en un DataFrame\n",
    "df = pd.DataFrame(lista_aux_comentarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el DataFrame a un CSV\n",
    "df.to_csv(f'Data/{contador_comentarios}_Comentarios.csv', sep=';', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
